import torch
import numpy as np
import os
import numpy as np
import torch
import os
import sys

from utils.data_utils import *
from utils.data import NucDataset  # è‡ªå®šä¹‰ PyTorch Dataset
from models.model_architectures import sei_model,SeiX_model
from utils.preprocessing import *
from utils.graph_utils import plot_auroc_auprc
from utils.preprocess import *
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, matthews_corrcoef
import psutil, os
from logomaker import Logo
from typing import List, Tuple
import matplotlib.pyplot as plt
from scipy.stats import mannwhitneyu

custom_colors = {
    'A': '#CC0000',
    'T': '#008000',
    'C': '#0000CC',
    'G': '#FFB300'
}

def save_seq_to_fasta(seq, chrom, start, region, save_path):
    """
    å°†æŒ‡å®šåŒºé—´çš„åºåˆ—ä¿å­˜ä¸ºæ ‡å‡†FASTAæ ¼å¼

    å‚æ•°ï¼š
        seq: å­—ç¬¦ä¸²åºåˆ—ï¼ˆATCGï¼‰ï¼Œé•¿åº¦ä¸º1024ï¼ˆæˆ–æ›´é•¿ï¼‰
        chrom: æŸ“è‰²ä½“å·ï¼ˆå¦‚ 'A07'ï¼‰
        start: åŸå§‹åºåˆ—å¯¹åº”çš„åŸºå› ç»„èµ·å§‹ä½ç½®ï¼ˆå³ seq[0] åœ¨åŸºå› ç»„ä¸Šçš„ä½ç½®ï¼‰
        region: (region_start, region_end)ï¼Œç›¸å¯¹äºåŸºå› ç»„åæ ‡ï¼ˆå³ä¿å­˜å“ªä¸ªåŒºåŸŸï¼‰
        save_path: è¾“å‡ºFASTAè·¯å¾„ï¼Œä¾‹å¦‚ "./output.fa"
    """
    region_start, region_end = region
    offset_start = start + region_start
    offset_end = start + region_end

    assert 0 <= region_start < region_end <= len(seq), "region è¶…å‡ºåºåˆ—è¾¹ç•Œ"

    region_seq = seq[region_start:region_end]
    header = f">{chrom}:{offset_start}-{offset_end}"

    with open(save_path, 'w') as f:
        f.write(header + '\n')
        f.write(region_seq + '\n')

    print(f"âœ… FASTA å·²ä¿å­˜è‡³: {save_path}ï¼Œé•¿åº¦: {len(region_seq)}bp")

def load_model_tags(tag_file_path):
    with open(tag_file_path) as f:
        tags = [line.strip() for line in f if line.strip()]
    return tags

def get_feature_column_index(target_name, tag_file):
    tags = load_model_tags(tag_file)
    if target_name not in tags:
        raise ValueError(f"ç‰¹å¾ '{target_name}' ä¸åœ¨æ¨¡å‹è¾“å‡ºæ ‡ç­¾ä¸­ï¼å¯é€‰å€¼åŒ…æ‹¬: {tags}")
    return tags.index(target_name)

def make_tag_dict(tag_file):
    # åŠ è½½æ ‡ç­¾æ–‡ä»¶ï¼Œå¹¶åˆ›å»ºæ ‡ç­¾å­—å…¸
    with open(tag_file) as f:
        tag_list = f.readlines()

    tag_dict = {item.strip(): index for index, item in enumerate(tag_list)}
    return tag_dict

def single_nucl_mutation(seq):
    """
    å¯¹åºåˆ—ä¸­çš„æ¯ä¸ªç¢±åŸºè¿›è¡Œå•ç¢±åŸºçªå˜ï¼Œè¿”å›çªå˜åçš„ç‹¬çƒ­ç¼–ç ã€‚
    åŒ…æ‹¬åŸå§‹åºåˆ—ï¼Œå…± 1 + 1024*3 = 3073 ä¸ªåºåˆ—ã€‚
    """
    db = ['A', 'C', 'G', 'T']
    seqlist = [seq]  # åŸå§‹åºåˆ—åœ¨æœ€å‰

    for i, nuc in enumerate(seq):
        for alt in db:
            if alt != nuc:
                alt_seq = seq[:i] + alt + seq[i+1:]
                seqlist.append(alt_seq)

    alt_pre = NucPreprocess(seqlist)
    X_alt = alt_pre.onehot_for_nuc()

    return X_alt


from Bio import SeqIO


def extract_seqs_from_fa_by_csv(fa_path, csv_path):
    """
    æ ¹æ® csv æ–‡ä»¶ä¸­å®šä¹‰çš„å¤šä¸ªåŒºåŸŸï¼Œä» fa æ–‡ä»¶ä¸­æ‰¹é‡æå–é•¿åº¦ä¸º 1024 çš„ç¢±åŸºåºåˆ—ã€‚

    å‚æ•°ï¼š
        fa_path: fasta æ–‡ä»¶è·¯å¾„ï¼ˆåŒ…å«å¤šæ¡æŸ“è‰²ä½“ï¼‰
        csv_path: CSV æ–‡ä»¶è·¯å¾„ï¼Œéœ€åŒ…å« 'chrom', 'start', 'end' ä¸‰åˆ—

    è¿”å›ï¼š
        List[str]: åºåˆ—åˆ—è¡¨ï¼ˆä¸ csv é¡ºåºä¸€è‡´ï¼‰
    """
    expected_len = 1024
    print(f"ğŸ“– åŠ è½½å‚è€ƒåŸºå› ç»„: {fa_path}")

    # é¢„è¯»å–æ‰€æœ‰æŸ“è‰²ä½“åºåˆ—
    chrom_seqs = {record.id: str(record.seq).upper() for record in SeqIO.parse(fa_path, "fasta")}
    print(f"âœ… è½½å…¥ {len(chrom_seqs)} æ¡æŸ“è‰²ä½“åºåˆ—")

    # è¯»å–csv
    df = pd.read_csv(csv_path)
    sequences = []

    for i, row in df.iterrows():
        chrom, start, end = str(row["chrom"]), int(row["start"]), int(row["end"])

        if chrom not in chrom_seqs:
            raise ValueError(f"[âŒ é”™è¯¯] åœ¨ {fa_path} ä¸­æœªæ‰¾åˆ°æŸ“è‰²ä½“: {chrom}")

        sub_seq = chrom_seqs[chrom][start:end]
        if len(sub_seq) != expected_len:
            raise ValueError(f"[âŒ é”™è¯¯] ç¬¬ {i} è¡Œ ({chrom}:{start}-{end}) æå–åˆ°åºåˆ—é•¿åº¦ä¸º {len(sub_seq)}ï¼Œä¸æ˜¯ 1024")

        sequences.append(sub_seq)

    print(f"âœ… æˆåŠŸæå– {len(sequences)} æ¡åºåˆ—ï¼ˆæ¯æ¡ 1024bpï¼‰")
    return sequences

def predict_ref_profiles_batch(
    seqs,                   # List[str]ï¼ŒATCGåºåˆ—ï¼Œæ¯æ¡é•¿åº¦ä¸º1024
    model_path,             # æ¨¡å‹è·¯å¾„
    model_tag_file,         # æ¨¡å‹ tag æ–‡ä»¶ï¼ˆå†³å®šè¾“å‡ºç‰¹å¾æ•°ï¼‰
    batch_size=512,
    device=torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
):
    """
    å¯¹ä¼ å…¥çš„ N æ¡åºåˆ—è¿›è¡Œéçªå˜é¢„æµ‹ï¼Œè¿”å›æ¯æ¡åºåˆ—çš„æ‰€æœ‰æŸ“è‰²è´¨ç‰¹å¾é¢„æµ‹å€¼ã€‚

    è¿”å›ï¼š
        numpy.ndarrayï¼Œshape = (N, num_features)
    """
    # Step 1: One-hot ç¼–ç 
    preprocessor = NucPreprocess(seqs)
    X_ref = preprocessor.onehot_for_nuc()  # shape: (N, 1024, 4)

    # Step 2: æ„å»º DataLoader
    ref_dataset = NucDataset(x=X_ref, y=None)
    ref_loader = DataLoader(ref_dataset, batch_size=batch_size, shuffle=False, num_workers=0)

    # Step 3: åŠ è½½æ¨¡å‹
    tag_dict = make_tag_dict(model_tag_file)
    num_features = len(tag_dict)
    model = sei_model.Sei(sequence_length=1024, n_genomic_features=num_features)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval()

    # Step 4: é¢„æµ‹
    predictions = []
    with torch.no_grad():
        for batch_inputs in ref_loader:
            batch_inputs = batch_inputs.to(device, dtype=torch.float)
            batch_inputs = batch_inputs.permute(0, 2, 1)  # (B, 4, 1024)
            batch_outputs = model(batch_inputs)
            predictions.append(batch_outputs.cpu().numpy())

    return np.concatenate(predictions, axis=0)  # shape: (N, num_features)

def predict_mutation_delta_by_split(seqs, model_path, model_tag_file, batch_size=512, device="cpu"):
    """
    æ”¯æŒå¤šä¸ªåºåˆ—çš„ ISM æ‰¹é‡é¢„æµ‹ï¼šref å’Œ mutation åˆ†åˆ«é¢„æµ‹

    è¿”å›ï¼š
        List[np.ndarray]: æ¯æ¡åºåˆ—çš„ Î” åˆ†æ•°æ•°ç»„ (3072, n_feature)
    """
    from torch.utils.data import DataLoader
    model_tag_dict = make_tag_dict(model_tag_file)
    n_feature = len(model_tag_dict)

    # Step 1: æ‹†åˆ†æ‰€æœ‰ ref å’Œ mutation ç¼–ç 
    X_refs = []
    X_muts = []

    for seq in seqs:
        assert len(seq) == 1024, f"åºåˆ—é•¿åº¦å¿…é¡»ä¸º1024ï¼Œå½“å‰ä¸º{len(seq)}"
        X_alt = single_nucl_mutation(seq)  # åŒ…å«ref + 3072çªå˜
        X_refs.append(X_alt[0])           # å–ç¬¬0è¡Œæ˜¯ref
        X_muts.append(X_alt[1:])            # å–ç¬¬1~3072è¡Œä¸ºçªå˜

    # å°†æ¯ä¸ªå°listä¸­çš„ tensor æå–å‡ºæ¥æ‹¼æ¥æˆä¸€ä¸ªå¤§ array
    # è½¬æ¢ä¸º NumPy åæ‹¼æ¥
    X_refs_all = np.stack([x.cpu().numpy() for x in X_refs], axis=0)  # shape: (N, 1024, 4)

    # æ‰å¹³åŒ–ï¼ŒæŠŠ X_muts ä¸­çš„æ‰€æœ‰çªå˜æ‰å¹³å±•å¼€
    flat_mut_list = []

    for mut_list in X_muts:
        for mut in mut_list:
            # mut åº”è¯¥æ˜¯ (1024, 4) çš„ Tensor æˆ– list
            if isinstance(mut, list):
                mut = torch.tensor(mut, dtype=torch.float32)
            flat_mut_list.append(mut)
    X_muts_all = torch.stack(flat_mut_list, dim=0).cpu().numpy()  # shape = (N*3072, 1024, 4)

    # Step 2: æ¨¡å‹åŠ è½½
    model = sei_model.Sei(sequence_length=1024, n_genomic_features=n_feature)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model = model.to(device)
    model.eval()

    def predict(X_all):
        dataset = NucDataset(x=X_all, y=None)
        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)
        all_preds = []
        with torch.no_grad():
            for inputs in loader:
                inputs = inputs.to(device, dtype=torch.float).permute(0, 2, 1)
                outputs = model(inputs).squeeze()
                if outputs.ndim == 1:
                    outputs = outputs.unsqueeze(0)
                all_preds.append(outputs.cpu().numpy())
        return np.concatenate(all_preds, axis=0)  # shape: (N, n_feature)

    # Step 3: æ‰§è¡Œé¢„æµ‹
    preds_ref = predict(X_refs_all)                # shape: (N, n_feature)
    preds_mut = predict(X_muts_all)                # shape: (N*3072, n_feature)

    # Step 4: è®¡ç®— Î” åˆ†æ•°
    delta_scores = []
    for i in range(len(seqs)):
        ref_i = preds_ref[i]                       # shape: (n_feature,)
        mut_i = preds_mut[i*3072:(i+1)*3072]       # shape: (3072, n_feature)
        delta = mut_i - ref_i                      # shape: (3072, n_feature)
        delta_scores.append(delta)

    return delta_scores  # List of (3072, n_feature)

def run_and_plot_boxplot(seqs_peak, seqs_nonpeak, model_path, model_tag_path, histone_name,
                         batch_func, result_prefix, result_path, title_suffix="", mutation=False, batch_size=512, device=None):
    """
    ç®€æ´å°è£…ï¼šå¯¹peakä¸non-peakåŒºåŸŸåºåˆ—è¿›è¡Œé¢„æµ‹ã€ç»Ÿè®¡ã€ç»˜å›¾

    å‚æ•°è¯´æ˜ï¼š
        seqs_peak: list[str]ï¼ŒPeakåŒºåŸŸATCGåºåˆ—
        seqs_nonpeak: list[str]ï¼ŒNon-PeakåŒºåŸŸATCGåºåˆ—
        model_path: æ¨¡å‹è·¯å¾„
        model_tag_path: æ ‡ç­¾è·¯å¾„
        histone_name: ç›®æ ‡ç»„è›‹ç™½åï¼ˆå¦‚ H3K4ME3ï¼‰
        batch_func: é¢„æµ‹å‡½æ•°ï¼ˆå¯ä»¥æ˜¯ predict_ref_profiles_batch æˆ– predict_mutation_delta_by_splitï¼‰
        result_prefix: è¾“å‡ºå›¾åƒå‰ç¼€
        title_suffix: å›¾æ ‡é¢˜è¡¥å……è¯´æ˜ï¼ˆå¦‚ "åŸå§‹é¢„æµ‹"ã€"ISMçªå˜"ï¼‰
        mutation: æ˜¯å¦ä¸ºISMçªå˜ï¼Œå½±å“ slicing é€»è¾‘
    """
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    import seaborn as sns
    from scipy.stats import mannwhitneyu

    def pval_to_star(p):
        if p < 0.001: return '***'
        elif p < 0.01: return '**'
        elif p < 0.05: return '*'
        else: return 'n.s.'

    tag_index = load_model_tags(model_tag_path).index(histone_name)

    # é¢„æµ‹
    pred_peak = batch_func(seqs_peak, model_path, model_tag_path, batch_size, device)
    pred_nonpeak = batch_func(seqs_nonpeak, model_path, model_tag_path, batch_size, device)

    if mutation:
        # å…ˆæ‹¼æ¥ list ä¸­çš„æ‰€æœ‰ ndarray
        peak_arr = np.concatenate(pred_peak, axis=0)  # shape = (NÃ—3072, F)
        nonpeak_arr = np.concatenate(pred_nonpeak, axis=0)

        # ç„¶åæå–å¯¹åº”ç‰¹å¾å¹¶å–ç»å¯¹å€¼
        vals_peak = np.abs(peak_arr[:, tag_index])
        vals_nonpeak = np.abs(nonpeak_arr[:, tag_index])
    else:
        vals_peak = np.abs(pred_peak[:, tag_index].flatten())
        vals_nonpeak = np.abs(pred_nonpeak[:, tag_index].flatten())

    # æ•´åˆ DataFrame
    df = pd.DataFrame({
        "Î”score (abs)": np.concatenate([vals_peak, vals_nonpeak]),
        "Region": ["Peak"] * len(vals_peak) + ["Non-Peak"] * len(vals_nonpeak)
    })

    # æ˜¾è‘—æ€§æ£€éªŒ
    stat, p_value = mannwhitneyu(vals_peak, vals_nonpeak, alternative="greater")

    # ç»˜å›¾
    plt.figure(figsize=(6, 6))
    sns.boxplot(data=df, x="Region", y="Î”score (abs)", width=0.5, palette="Set2", showfliers=False)
    plt.title(f"{histone_name} {title_suffix}", fontsize=14)
    plt.ylabel("")
    plt.xlabel("")
    plt.tick_params(axis='both', labelsize=20)
    plt.tight_layout()
    save_path = f"{result_prefix}_{'mutation' if mutation else 'itself'}.png"
    plt.savefig(os.path.join(result_path, save_path), dpi=300)
    plt.close()
    print(f"âœ… å›¾å·²ä¿å­˜è‡³: {save_path}")


def predict_with_mutation_scan(seqs, model_path, model_tag_file, device, batch_size=512):
    """
    æ¥æ”¶ä¸€ä¸ª 1024bp çš„åºåˆ—ï¼Œæ‰§è¡Œçªå˜æ‰«æå¹¶è¿”å› 3073Ã—n_feature çš„é¢„æµ‹çŸ©é˜µ

    å‚æ•°ï¼š
        seq (str): 1024 é•¿åº¦çš„ ATCG åºåˆ—
        model_path (str): è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„
        device (torch.device): 'cuda' or 'cpu'
        n_feature (int): æ¨¡å‹è¾“å‡ºç‰¹å¾ç»´åº¦
        batch_size (int): é¢„æµ‹æ‰¹å¤§å°

    è¿”å›ï¼š
        total_pre (np.ndarray): shape = (3073, n_feature)
    """

    # Step 1: å•ç¢±åŸºçªå˜å¹¶ç¼–ç 
    X_alt = single_nucl_mutation(seq)
    print(f"çªå˜ç¼–ç åºåˆ—æ€»æ•°: {len(X_alt)}")

    # Step 2: æ„å»º DataLoader
    pre_dataset = NucDataset(x=X_alt,  y=None)
    pre_loader = DataLoader(dataset=pre_dataset, batch_size=batch_size, shuffle=False, num_workers=0)

    model_tag_dict = make_tag_dict(model_tag_file)
    model = sei_model.Sei(sequence_length=1024, n_genomic_features=len(model_tag_dict))  # ä»ç„¶ä½¿ç”¨å®Œæ•´çš„ tag_dict

    # Step 3: åŠ è½½æ¨¡å‹
    model.load_state_dict(torch.load(model_path))
    model.to(device)
    model.eval()

    # Step 4: æ‰§è¡Œé¢„æµ‹
    predictions = []
    with torch.no_grad():
        for inputs in pre_loader:
            inputs = inputs.to(device, dtype=torch.float)
            inputs = inputs.permute(0, 2, 1)
            outputs = model(inputs)
            outputs = outputs.squeeze()
            if outputs.ndim == 1:
                outputs = outputs.unsqueeze(0)
            predictions.append(outputs.cpu().numpy())

    predictions = np.concatenate(predictions, axis=0)

    return predictions

def plot_single_feature_mutation_delta(pred_scores, start=0, figsize=(30, 5)):
    """
    å¯è§†åŒ–å•ä¸ªæŸ“è‰²è´¨ç‰¹å¾åœ¨ 1024 ä¸ªç¢±åŸºä¸Šçªå˜å¸¦æ¥çš„ Î”score

    å‚æ•°ï¼š
        pred_scores: shape=(3073,) æˆ– (3073, 1) çš„ arrayï¼ŒåŸå§‹ + çªå˜åºåˆ—çš„é¢„æµ‹å€¼
        start: èµ·å§‹åæ ‡ï¼ˆç”¨äºæ¨ªè½´æ ‡æ³¨ï¼‰
        figsize: å›¾åƒå°ºå¯¸
    """

    pred_scores = np.ravel(pred_scores)  # ç¡®ä¿æ˜¯ä¸€ç»´å‘é‡
    assert len(pred_scores) == 3073, "é¢„æµ‹å€¼æ•°é‡å¿…é¡»ä¸º 3073ï¼ˆ1åŸå§‹ + 1024Ã—3çªå˜ï¼‰"

    ref_score = pred_scores[0]
    mut_scores = pred_scores[1:]  # shape: (3072,)
    delta_scores = mut_scores - ref_score

    # æ„é€ ç»˜å›¾æ•°æ®
    df_plot = pd.DataFrame({
        "delta": delta_scores,
        "alt": ["alt" + str(i % 3 + 1) for i in range(3072)],
        "pos": [i // 3 + 1 for i in range(3072)]
    })

    # å¯è§†åŒ–
    plt.figure(figsize=figsize)
    sns.lineplot(data=df_plot, x="pos", y="delta", hue="alt", palette="tab10")
    plt.axhline(0, color='gray', linestyle='--')
    plt.xticks(range(0, 1024, 128), range(start, start + 1024, 128))
    plt.xlabel("Genomic Position")
    plt.ylabel("Î” Score (Mutated - Original)")
    plt.title("Single Nucleotide Mutation Impact on Feature")
    plt.tight_layout()
    plt.show()

def build_mutation_matrix(delta_scores, ref_seq, species_name, histone_name, result_path=".", start=0, region=(399, 601), figsize=(30, 6)):
    """
    æ„å»ºå¹¶ç»˜åˆ¶çªå˜æ•æ„Ÿæ€§çƒ­å›¾çŸ©é˜µï¼ˆæ¯ä¸ªä½ç‚¹ä¸‰ç§çªå˜ + å‚è€ƒç¢±åŸºï¼‰

    å‚æ•°ï¼š
        delta_scores: shape=(3072,) çš„ arrayï¼Œè¡¨ç¤ºæ¯ä¸ªçªå˜åçš„ Î” åˆ†æ•°ï¼ˆmut - refï¼‰
        ref_seq: åŸå§‹ 1024bp çš„ ATCG åºåˆ—ï¼ˆé•¿åº¦å¿…é¡»ä¸º 1024ï¼‰
        start: èµ·å§‹åæ ‡ï¼ˆç”¨äºåæ ‡è½´ï¼‰
        region: çƒ­å›¾ç»˜åˆ¶åŒºé—´ï¼Œå¦‚ (399, 601)
        figsize: å›¾åƒå°ºå¯¸
        save_path: è‹¥æä¾›è·¯å¾„åˆ™ä¿å­˜å›¾åƒ

    è¿”å›ï¼š
        values_result: shape=(1024, 4) çš„çªå˜çƒ­å›¾çŸ©é˜µï¼ˆ0 è¡¨ç¤ºå‚è€ƒç¢±åŸºï¼‰
    """
    assert len(delta_scores) == 3072, "å¿…é¡»ä¸º 1024Ã—3 ä¸ªçªå˜ Î”score"
    assert len(ref_seq) == 1024, "å‚è€ƒåºåˆ—é•¿åº¦å¿…é¡»ä¸º 1024"

    # Step 1ï¼šæ„é€  dataframe è¡¨æ ¼
    df = pd.DataFrame({
        "delta": delta_scores,
        "pos": np.repeat(np.arange(1, 1025), 3),  # 1~1024 æ¯ä¸ªä½ç‚¹ 3 ä¸ªçªå˜
        "alt": ["alt" + str(i % 3 + 1) for i in range(3072)]
    })

    # Step 2ï¼šå°†æ¯ä¸ªä½ç‚¹çš„çªå˜ç»“æœè½¬ä¸ºçŸ©é˜µï¼Œå¹¶è¡¥å……å‚è€ƒç¢±åŸºä¸º 0
    ref_db = ['A', 'C', 'G', 'T']
    values_result = []

    for i in range(1024):
        # æ‰¾å‡ºä¸æ˜¯å‚è€ƒç¢±åŸºçš„ä¸‰ä¸ªç¢±åŸºï¼ˆæ¨¡æ‹Ÿ altï¼‰
        ref_base = ref_seq[i].upper()
        alt_bases = [b for b in ref_db if b != ref_base]
        delta_vals = df.iloc[i * 3:i * 3 + 3]["delta"].values

        # å°†çªå˜åˆ†æ•°æ’å…¥å‚è€ƒç¢±åŸºä½ç½®ï¼ˆå‚è€ƒç¢±åŸºä¸º 0ï¼‰
        ref_idx = ref_db.index(ref_base)
        values_result.append(np.insert(delta_vals, ref_idx, 0))

    values_result = np.array(values_result)  # shape = (1024, 4)

    # Step 3ï¼šç»˜å›¾
    plt.figure(figsize=figsize)
    region_start, region_end = region
    sns.heatmap(
        values_result[region_start:region_end, :].T,
        cmap='vlag',
        center=0,
        xticklabels=range(region_start + start, region_end + start),
        yticklabels=ref_db
    )

    # è‡ªåŠ¨æ§åˆ¶åˆ»åº¦é—´éš”
    region_length = region_end - region_start
    max_ticks = 20  # æœ€å¤šæ˜¾ç¤º 20 ä¸ªåˆ»åº¦
    tick_step = max(1, region_length // max_ticks)

    xtick_pos = range(0, region_length, tick_step)
    xtick_labels = [region_start + start + i for i in xtick_pos]
    plt.xticks(ticks=xtick_pos, labels=xtick_labels, rotation=0)


    plt.xlabel("Genomic Position")
    plt.ylabel("Nucleotide")
    plt.title("Single Nucleotide Mutation Sensitivity Matrix")
    plt.tight_layout()
    save_path = os.path.join(result_path, f"{species_name}_{histone_name}_{region_start+ start}_{region_end + start}_mutation_matrix.png")
    if save_path:
        plt.savefig(save_path, dpi=300)
        print(f"çƒ­å›¾å·²ä¿å­˜è‡³: {save_path}")
    else:
        plt.show()

    return values_result

def plot_reference_base_importance(values_result, ref_seq, start=0, region=(399, 601), figsize=(30, 6), species_name="", histone_name="", result_path="."):
    """
    ç»˜åˆ¶æ¯ä¸ªä½ç½®å‚è€ƒç¢±åŸºçš„é‡è¦æ€§çƒ­å›¾

    å‚æ•°ï¼š
        values_result: shape=(1024, 4)ï¼Œçªå˜å½±å“çŸ©é˜µï¼ˆå«å‚è€ƒç¢±åŸºä¸º 0ï¼‰
        ref_seq: åŸå§‹åºåˆ—ï¼ˆé•¿åº¦ä¸º 1024ï¼‰
        start: åŸºå› ç»„èµ·å§‹åæ ‡
        region: å¯è§†åŒ–èŒƒå›´ (é»˜è®¤ 399~600)
        save_path: æ˜¯å¦ä¿å­˜å›¾åƒ
    """
    ref_db = ['A', 'C', 'G', 'T']
    region_start, region_end = region

    # æ¯ä¸ªä½ç½®åªæœ‰ä¸€ä¸ªç¢±åŸºé‡è¦æ€§å€¼ï¼Œå…¶ä½™ä¸º 0
    logo_result = []
    for i in range(1024):
        ref_base = ref_seq[i].upper()
        ref_idx = ref_db.index(ref_base)
        alt_vals = np.delete(values_result[i], ref_idx)  # å–éå‚è€ƒç¢±åŸºçš„çªå˜å€¼
        abs_sum = np.sum(np.abs(alt_vals))

        temp = [0] * 4
        temp[ref_idx] = abs_sum
        logo_result.append(temp)

    logo_result = np.array(logo_result)

    # ç”»å›¾
    plt.figure(figsize=figsize)
    sns.heatmap(
        logo_result[region_start:region_end, :].T,
        cmap="vlag",
        center=0,
        xticklabels=range(region_start + start, region_end + start),
        yticklabels=ref_db,
        cbar_kws={"label": "Reference Base Importance"}
    )

    # è‡ªåŠ¨ç¨€ç– X è½´åæ ‡
    region_length = region_end - region_start
    max_ticks = 20
    tick_step = max(1, region_length // max_ticks)
    xtick_pos = range(0, region_length, tick_step)
    xtick_labels = [region_start + start + i for i in xtick_pos]
    plt.xticks(ticks=xtick_pos, labels=xtick_labels, rotation=0)

    plt.title("Reference Base Importance (Î”score sum of mutations)")
    plt.xlabel("Genomic Position")
    plt.ylabel("Reference Base")
    plt.tight_layout()

    save_path = os.path.join(result_path,
                             f"{species_name}_{histone_name}_{region_start + start}_{region_end + start}_ref_base_importance.png")
    if save_path:
        plt.savefig(save_path, dpi=300)
        print(f"çƒ­å›¾å·²ä¿å­˜è‡³: {save_path}")
    else:
        plt.show()

if __name__ == "__main__":
    # è®¾ç½®è®¾å¤‡
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # model_path = "../../../../models/saved_models/merged_tag_HFT_BC/ath/mergedtag_ath_HFT_BC_20250312_203749_1024_nip_feature7.model"
    model_path = "../../../../models/saved_models/merged_tag_HFT_BC/cross/Score_regression_cross_osa_zma_HFT_BC_20250312_171305_1024_nip_feature7.model"
    model_tag_path = "shuffle_tag_osa_zma.txt"
    result_path = "./sorghum_bicolor"
    species_name = "sorghum_bicolor"
    histone_name = "H3K4ME3"
    region=(399, 601)
    region_start, region_end = region
    peak_csv_file = os.path.join(result_path,"SbMC_H3K4me3_Rep2.cpm_top50_peaks.csv")
    nonpeak_csv_file = os.path.join(result_path, "SbMC_H3K4me3_Rep2.cpm_top50_flanking_nonpeaks.csv")
    # è¯»å– ATCG åºåˆ— peakå³°å€¼åŒºåŸŸ
    peak_seqs = extract_seqs_from_fa_by_csv(fa_path=f"D:\\data\\tag_file\\fa\\{species_name}\\{species_name}.fa",
                                      csv_path=peak_csv_file)
    nonpeak_seqs = extract_seqs_from_fa_by_csv(fa_path=f"D:\\data\\tag_file\\fa\\{species_name}\\{species_name}.fa",
                                               csv_path=nonpeak_csv_file)
    # # éçªå˜é¢„æµ‹
    run_and_plot_boxplot(
        seqs_peak=peak_seqs,
        seqs_nonpeak=nonpeak_seqs,
        model_path=model_path,
        model_tag_path=model_tag_path,
        histone_name=histone_name,
        batch_func=predict_ref_profiles_batch,
        result_prefix=f"{histone_name}_compare",
        result_path=result_path,
        title_suffix="Prediction Score",
        mutation=False,
        device=device
    )

    # # çªå˜é¢„æµ‹
    run_and_plot_boxplot(
        seqs_peak=peak_seqs,
        seqs_nonpeak=nonpeak_seqs,
        model_path=model_path,
        model_tag_path=model_tag_path,
        histone_name=histone_name,
        batch_func=predict_mutation_delta_by_split,
        result_prefix=f"{histone_name}_compare",
        result_path=result_path,
        title_suffix="In Situ Mutation Effect",
        mutation=True,
        device=device
    )

    # results_peak_itself = predict_ref_profiles_batch(
    #     seqs=peak_seqs,
    #     model_path=model_path,
    #     model_tag_file=model_tag_path,
    #     batch_size=512
    # )
    # results_peak_Mutation = predict_mutation_delta_by_split(
    #     seqs=seqs,
    #     model_path=model_path,
    #     model_tag_file=model_tag_path,
    #     batch_size=512,
    #     device=torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    # # )
    # # è¯»å– ATCG åºåˆ— nonpeakåŒºåŸŸ
    # nonpeak_seqs = extract_seqs_from_fa_by_csv(fa_path=f"D:\\data\\tag_file\\fa\\{species_name}\\{species_name}.fa",
    #                                    csv_path=nonpeak_csv_file)
    # results_nonpeak_itself = predict_ref_profiles_batch(
    #     seqs=nonpeak_seqs,
    #     model_path=model_path,
    #     model_tag_file=model_tag_path,
    #     batch_size=512
    # )
    # results_nonpeak_Mutation = predict_mutation_delta_by_split(
    #     seqs=seqs,
    #     model_path=model_path,
    #     model_tag_file=model_tag_path,
    #     batch_size=512,
    #     device=torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    # )

    # # ä¿å­˜
    # np.save("results_peak.npy", results_peak)
    # np.save("results_nonpeak.npy", results_nonpeak)

    # === 1. åŠ è½½æ•°æ® ===
    # results_peak = np.load("results_peak.npy")
    # results_nonpeak = np.load("results_nonpeak.npy")

    # # === 2. é€‰æ‹©ä½ å…³æ³¨çš„æŸ“è‰²è´¨ç‰¹å¾ ===
    # target_index = load_model_tags(model_tag_path).index(histone_name)
    #
    # # å–å‡ºè¯¥ç‰¹å¾çš„ Î”score å€¼ï¼ˆå·²ç»æ˜¯ mut - refï¼‰
    # delta_peak = results_peak_itself[:, target_index]
    # delta_nonpeak = results_nonpeak_itself[:, target_index]
    #
    # # === 3. ç»å¯¹å€¼ï¼šè¡¨ç¤ºå˜åŒ–å¹…åº¦ ===
    # abs_peak = np.abs(delta_peak).flatten()
    # abs_nonpeak = np.abs(delta_nonpeak).flatten()
    #
    # # === 4. æ•´åˆä¸º DataFrame ===
    # df = pd.DataFrame({
    #     "Î”score (abs)": np.concatenate([abs_peak, abs_nonpeak]),
    #     "Region": ["Peak"] * len(abs_peak) + ["Non-Peak"] * len(abs_nonpeak)
    # })
    #
    # # ==== ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ ====
    # stat, p_value = mannwhitneyu(abs_peak, abs_nonpeak, alternative="greater")
    # print(f"ğŸ“Š Mann-Whitney U æ£€éªŒ: p = {p_value:.4e}")
    #
    # # ==== ç»˜å›¾ ====
    # plt.figure(figsize=(6, 6))
    # sns.boxplot(data=df, x="Region", y="Î”score (abs)", width=0.5, palette="Set2", showfliers=False)
    # # sns.stripplot(data=df, x="Region", y="Î”score (abs)", color=".3", size=1.5, alpha=0.15)
    #

